Computer Science http dx doi org csci Dominik AdamskiGrzegorz Jab lon skiHARDWARE AWARE TILING OPTIMIZATIONFOR MULTI CORE SYSTEMSAbstract This paper presents proposal for new tool that improves tiling efficiencyfor given hardware architecture
This article also describes the correlationbetween the changing hardware architecture and methods of software optimization
The first chapter includes short description of the change in hardwarearchitecture that has occurred over the past ten years
The second chapterprovides an overview of the tools that will be used in further research
Thesubsequent sections contain description of the proposed hardware aware toolfor optimal tiling Keywords LLVM tiling data locality polyhedral modelCitation Computer Science Dominik Adamski Grzegorz Jab lon ski
IntroductionFor many decades the speedup of program execution has been achieved through thespeedup of processor clocks
The rapid growth of processor clock frequencies causeda relatively small change in the architecture of processors
Rapid growth of processorfrequency stopped in due to heat dissipation issues
Since that time hardwaremanufacturers have shifted towards multi core architectures
They introduced advanced multi level cache memory systems and multiplied the number of processor coresin single CPU unit
These changes are reflected in more sophisticated processorarchitecture and increasing number of transistors used inside single CPU Unfortunately the shift in hardware architecture does not provide an automaticspeedup of software that has been optimized for sequential processing
Consequently any new optimization method should take into account the new target hardwarearchitectures
Modern compilers should support parallel task execution and theyshould provide new optimization methods that would automatically detect parallelregions and optimize them in order to fully utilize the hardware resources
There isa strong need to develop such techniques of code optimization that could be easilydeployed on various hardware architectures on one hand and take into account themany specific hardware features that are different for every target platform on theother
Optimization methods that meet these goals can be easily deployed in variousareas of the computer industry
They can be applied to mobile devices where theycan reduce power consumption and prolong battery life
More effective software fordata centers can reduce the cost of energy while also decreasing data access time
Memory optimizationThe rapid increase of processor computation power has not been followed by proportional memory speedup
As consequence the overall speed of program executionis limited by the memory latency
Multilevel memory organization allows us toreduce the gap between memory and processor performance
Modern processors areequipped with small amount of quick cache memory placed near the processor coreand larger amount of slower cache shared by the many cores Unfortunately no general model for cache memory organization has come alongwith the increased variety of processor architectures
GPU processors are characterized by multiple cores with small amount of shared cache memory and distributedmemory model while CPU processors use uniform memory model with largeamount of multilevel cache memory
In general memory usage optimization shouldaim to exploit the internal cache memory instead of calling data from the slow external RAM memory
The number of cache misses should be minimized as well as thenumber of memory transfesr between the respective memory units Hardware aware tiling optimization for multi core systems
Data localityDesigners of processing units have introduced multilevel system of memory organization to improve memory efficiency
They decided to equip processing unitswith small amount of fast cache memory
In modern CPUs there are multiple levelsof cache memory characterized by different sizes and speeds
The lower tiers of cacheare the fastest but their sizes are the smallest
Usually they cooperate with only onecore
The higher tiers of cache are often shared between multiple cores
Their sizesare bigger but they are slower than the cache from the lower tier
If given variableis used many times by processor it is placed in the lower cache
In such case thewaiting time for data is reduced allowing the processor to perform faster calculations If the processor requests data that is not inside the cache memory then cache missevent occurs
In such case the processor should wait until the data is transportedfrom the RAM memory
This situation substantially reduces the performance of theprocessing units
TilingOne of the available techniques for improving memory performance is tiling The main aim of this optimization is to maximally reuse the fastest cache memory This goal can be achieved by the division of large loop iteration space into smallerrectangular parts tiles
Listing illustrates this tiling optimization
The size of thetiles should be chosen in such way that cache misses are minimized
It has beenproven that tile size should be chosen in such way that the number of cache missesis minimized for all levels of cache memory input source code for int for int optimized source code for int for int for int ii ii min ii for int jj jj min jj ii jj ii jj ii jj There are many factors that should be taken into account while choosing theoptimal tile size
This is largely dependent on the target hardware platform
giventile size can provide speedup of calculations for one target while the same tilingconfiguration can cause significant slowdown for another target platform
On theother hand the optimal tile size depends on the iteration space and memory accesspatterns that are defined by the developer
In the authors opinion it is also not possible to determine an accurate analytical model for optimal tiling prediction becauseof the complexity of hardware systems and the difficulties with the static analysis ofinput source code that should be optimized Dominik Adamski Grzegorz Jab lon ski
State of the artCurrently code optimization for multicore architectures is at the center of interest formany research teams and large companies
They try to develop tools that would fullyutilize the computational power of their multicore systems
Their research effort isfocused on tools for input code analysis
They have also proposed new techniques forcode optimization
These techniques include the automatic parallelization of inputcode and reduction in cache misses
Polyhedral modelNowadays major compilers like GCC LLVM ICC and MSVC are equipped withtools for detection loops that can be parallelized
ICC and MSVC compilers are commercial products and their sources are not publicly available
For this reason it isnot possible to accurately assess the advantages and drawbacks of algorithms implemented in these products
GCC and LLVM compilers are open source and there aresome projects like Graphite for GCC and Polly for LLVM that use mathematicalconcept polyhedrons for detecting parallel regions of input code The main idea of the polyhedral model is to describe loops and loop bodies interms of mathematical equations
Loop boundary conditions are modeled aslinear functions that limit iteration space
The dimension of iteration space is equalto the number of nested loops
All data accesses inside of loop body are described interms of iteration space coordinates
This mathematical model is used by optimizerswho are trying to find the best schedule for given loop Tools for automatic code parallelization provide analytical methods for detectingwhether given set of loops can be executed in parallel
This information is important for finding an optimal loop tiling schedule through broadening of the searchspace
It is possible to reorder loops in parallel region to increase data locality Such transformation can simplify tiling analysis as consequence the most appropriate tiling size can be found faster
The Polly compiler is one of the tools forautomatic parallelization that can reorder sequence of parallel loops for improveddata locality
It also supports fixed tile size optimization but such an optimization is not always profitable
Unfortunately Polly optimizations do not always leadto more effective software
For some cases tiling optimization decreases the speed ofexecution of the programs
Analytical approachThe analytical approach for finding optimal tile size is based on analysis of the inputsource code and target hardware
Section of Figure illustrates this method ofoptimization
During the compilation process the compiler should decide how to tilethe loops so that the number of cache misses is minimized
The problem of analyticallyfinding the best partition of data in the general case for multilevel system of cachememory is classified as NP hard
It is not possible to determine in finite timeHardware aware tiling optimization for multi core systems how to place program data into the computer memory so that the time necessary fordata transport is minimal
The main difficulty lies in number of combinations thatshould be analyzed
Therefore analytical models only cover some special cases forwhich it is possible to determine the optimal data schedule Insert runtime callbacks compileExecuteapplicationAnalyze optimize in runtimesource codeBinarycodePerformancedataOptimizedcodeOptimize compileExecuteapplicationsource codeBinarycodeABFigure
Scheme of statistical and analytical approach of optimization Analytical models can be divided into two subcategories
The first subcategorycontains all models that predict optimal tile size for strictly defined input source codepatterns
They try to match the input code with those given loop patterns for whichit is possible to find an optimal tile size
The second category is based on someheuristic simplification
The hardware is modeled in simplified way
Such simplification allows us to find the suboptimal tile size
The range of simplification is strictlycombined with the quality of optimization
More general models find suboptimal tileresults faster
For these models there is large risk of obtaining poor optimizationresults
On the other hand more sophisticated models require increased computation and the time for finding suboptimal results may be unacceptably long
Statistical approachStatistic methods for finding suboptimal tile sizes have also been proposed They try to predict the optimal tile size on the basis of previous results of execution ofan optimized loop
Section of Figure illustrates this approach
This propositionrequires special runtime that gathers information about previous tile sizes andtheir corresponding execution times
Every time an optimized loop is executed theruntime tries to provide the most effective tile size
This approach does not includeany theoretical models and it may require many invocations of tiled loops to find theoptimal tile size
Other approachesSome researchers propose shapes of tiling other than rectangular
proposed hexagonal shape of tiles for GPU code
Another approach was introduced Dominik Adamski Grzegorz Jab lon skiby Kong et al they proposed that the minimization of cache misses can be achievednot by data tiling but by dynamic dataflow parallelization
Base tools for hardware aware tilingAs mentioned in the previous section there are already some tools that try to optimizethe data locality in loops
They exist as separate tools and each of these tools hasits strong and weak points
In the authors opinion it is worth combining all ofthese methods into one tool
This new tool should be based on Polly compiler itsruntime should measure cache misses by the PAPI library and it should be tested onthe Polybench benchmark
LLVM frameworkThe LLVM project was started as an academic tool for multi stage optimization Nowadays it is one of the leading open source compiler projects
It is entirely writtenin and characterized by modular design
It also provides well documentedAPI
These features have made LLVM an oft chosen framework for many compilerprojects
Figure presents the internal relationship between LLVM modules FrontendAda FrontendFortran FrontendX BackendARM BackendPowerPCBackendCommonOptimizerCAdaFortranARMPowerPCX Figure
LLVM architecture Front end modules are responsible for converting input source code into simplerform for analysis intermediate IR code
IR code is independent from high level inputlanguage
The simplified syntax of IR code helps make data and control flow analysiseasier as compared to source code analysis
It is used for hardware independentoptimization
All types of IR optimization are executed sequentially
The order ofexecution is determined by Pass Manager which analyzes the dependencies betweenpasses
Optimized IR code is transferred to backend modules that generate targetspecific binary code Hardware aware tiling optimization for multi core systems
Polly compilerThe Polly compiler is project based on the LLVM framework
This compiler describes loops in terms of mathematical equations if it detects that some part of the codecan be parallelized then it uses the simplex method for finding the best schedule andthen generates parallelized code The Polly compiler automatically detects regions of IR code that can be parallelized
The code that is ready for parallelization must satisfy the following conditions These conditions allow the compiler to freely rearrange the order of statementexecution
Such rearrangement is necessary for tiling optimization
If loop isparallelizable then loop tiling optimization can be safely performed Each detected parallel region is described by the Static Control Part SCoP object in Polly
These objects define the iteration space of parallel loops memoryaccess patterns inside the loops and data dependency between elements of the loops This information is used as the input for polyhedral optimizers that calculate anoptimal schedule for given SCoP
Figure presents the described architecture ofPolly LLVM Polly LLVM IRSCoP detection TransformationsScoplib Import ExportLLVM IRCode generationVectorizer BackendOpenMP parallel backendFigure
Architecture of Polly compiler Dominik Adamski Grzegorz Jab lon ski
PAPI libraryThe PAPI library provides tools for the accurate measurement of optimized loops It provides an interface for gathering information about the actual number of cachemisses and time of loop execution
This data plays an important role in the assessmentof the quality of optimized loops
If the tile size is badly chosen then the number ofcache misses will be high
PolybenchPolybench is set of benchmarks with parallel kernels
These kernels correspondto popular matrix operations like matrix multiplication the Fourier transform matrixcorrelation or decomposition
Polybench source code will be used as the referencebenchmark for the proposed approach for finding optimal tile sizes
Proposed solutionIt should be noticed that both the statistical and analytical approaches have somedrawbacks
Theoretical considerations about optimal tile size cannot give an exactanswer on which tile size is the best and the statistical approach requires multipleexecution of an optimized loop and this method does not always provide speedupin loop execution
On the other hand the polyhedral analysis used for finding anoptimal loop schedule for the Polly compiler can be time and memory consuming and it does not always provide the best result In the authors opinion it is worth combining the tools from static loop optimization with those from dynamic tile selection
The Polly compiler will be used forthe static analysis of input source code
It will detect the ready for parallelizationregions of the IR code and it can propose new schedule of loop statements
Alloptimizations made by Polly are described by the SCoP object which contains important data about memory access patterns iteration space data dependency andthe proposed loop schedule
This information will be saved in output binary codeand will be read by runtime functions that are responsible for choosing the proper tilesize
The choice of optimal tile size should be based on the heuristic data gatheredfrom previous executions and analytical data from the static code analysis
Figure illustrates the proposed solution The main aim of such an approach is to provide more data to the tile selectionmechanism
In the authors opinion it is the only way to combine static and dynamicanalysis results
It is expected that such combination will give more accuratemodel that will properly estimate the optimal size of the loop tiling
The proposedtile size prediction method algorithm will not limit any other polyhedral optimization Tiled code can be still parallelized or vectorized
The described optimization methodworks on IR code so it can be combined with the machine specific optimization madeby the target specific compiler backend Hardware aware tiling optimization for multi core systems RuntimeSCoPInstrumentationPassInput SourceCodeProgramoutputCurrent settings SCoP informationPolyhedralAnalysisBinaryProgramNew tile sizeInstrumentedSCoPDetectedSCoPFigure
Architecture of proposed solution The runtime algorithm used to calculate the optimal tile size has not been specified
In the authors opinion it should be done in the last phase of research
First the mechanism for saving static analysis results in the output binary code should beimplemented
Without this mechanism it is not possible to check which artificialintelligence algorithm predicts the optimal tile size in the best way The proposed approach allows us to shorten selection time by adding the moredetailed code description obtained by the polyhedral analysis into the dynamic runtime selection algorithm
It is expected that the compile time will be remain the sameas for the standard polyhedral optimization
Runtime overhead can increase duringprogram execution as compared to simple heuristic models because more analysisshould be done for choosing the best tile size
On the other hand more sophisticatedmethod of finding the best tile size could reduce the number of code executions neededto find the optimal tile size This project also requires some changes in the LLVM code
new pass should beadded that will automatically insert runtime callbacks into the optimized loops
Thesecallbacks should automatically adjust the tile size based on the previous optimizationresults and information about the hardware
Target platformsToday hardware manufacturers offer multiple solutions for calculation acceleration Their architecture is different and it is worth providing general approach for findingthe approximate optimal tile size
Currently there are three main trends in the designof computing efficient systems
Each of them is different and runtime should ask forspecific values of parameters for each platform separately Intel has proposed new concept of processor architecture it is called the ManyIntegrated Core MIC architecture
This is characterized by multiple general purposeprocessors that share cache memory
In comparison to Haswell some cores play therole of coprocessor
Their role is flexible and can work in many configurations The type of operation mode depends on the type of processed algorithm
If the algorithm is easily parallelizable then the host processors can offload portion of the Dominik Adamski Grzegorz Jab lon skicalculations to the coprocessors
If the code cannot be executed concurrently thenonly one host processor should work
Tiling runtime should take into account howmany coprocessors are available how the workload should be divided by the cores and which mode of of operation is most suitable GPU systems are characterized by distributed memory systems
The host processor can offload calculations to the GPU
The offloading procedure requires datatransfer between the CPU and GPU memory
This transfer strongly affects the speedof the calculations
Moreover the processing units on the GPU are optimized forstream processing
The tiling runtime should take into account the numberof threads available on the target GPU
The best tile size should effectively minimizethe number of branches and it should allow as many threads as possible to executethe calculations in parallel The third target platform is the combination of traditional CPU processorwith Field Programmable Gate Array FPGA device such as Xilinx ZynQ
Thisapproach allows us to offload calculations to device that can be easily tailored tothe end user computational needs
Recent research shows that tiling can improveusage of the available hardware
The runtime selecting the best tile size for theFPGA device should take into account not only the results of code analysis butalso the available resources number of available gates memory space and memorybandwidth
Due to the long time necessary to program an FPGA device it wouldprobably be impossible to tune the tile size during runtime
For this platform runtimecan only gather execution data like the size of the used resources or time of kernelexecution and it should propose the best tile size when the kernel code is once againrecompiled to bitstream code and then loaded into the FPGA device
Proof of conceptThis section presents the proof of concept results
The methodology was as follows function presented in the listing below was manually tiled
For each tested tilesize the time of function execution and number of data cache misses was recordedby the PAPI functions
They were inserted into the beginning and at the end of thetest function code void test function int int int int int int PB for PB for PB for PB for PB Hardware aware tiling optimization for multi core systems The Polly compiler detects that both loops can be described as one SCoP
Asa consequence it is possible to freely interchange the loop order
There are twovariants of tiling optimization examined the first concerns the tiling of each loopseparately void test function int int int int int int PB int TILE int TILE TILE and TILE define tile size for PB TILE for PB TILE for ii ii MIN TILE PB ii for jj jj MIN TILE PB jj ii ii ii jj jj for PB TILE for PB TILE for ii ii MIN TILE PB ii for jj jj MIN TILE PB jj ii ii ii jj jj The Polly compiler can propose that these statements ii ii ii jj jj and ii ii ii jj jj can be combined into one loop
For this reason the following tiling schedule was alsoanalyzed void test function int int int int int int PB int TILE int TILE TILE and TILE define tile size for PB TILE for PB TILE for ii ii MIN TILE PB ii for jj jj MIN TILE PB jj ii ii ii jj jj ii ii ii jj jj Dominik Adamski Grzegorz Jab lon ski
Hardware platformsThe code was compiled by gcc and executed without any parallel optimization ontwo platforms
The first one was an Intel
This CPU has MB of level datacache
This PC is equipped with GB of DDR RAM memory
The last level cachememory is shared between four cores
The first and second levels of cache memoryare dedicated to one core
The second platform was an Intel Core Duo with GB of DDR RAM memory
This is processor that was designed in fornotebooks
It is equipped with level MB data cache memory
Both platforms runon Ubuntu
Empirical resultsThis section includes the empirical results of tiling efficiency
The first group of plotsshows the dependencies between data cache misses and tile size
The second group ofplots shows the dependencies between time of kernel execution and tile size The performed tests show that tiling optimization is hardware dependent
Figures and show that there is wide range of tile sizes for which the time ofexecution is close to minimal
This can be explained by the fact that the number ofcache misses is comparable for most tile sizes Figures Time of execution for Intel Core Duo processor deteriorates when tile isequal to
For this case the processor executes many branch instructions that causea significant slowdown
If tile is equal to then the number of cache misses isconsiderably high
This situation can be explained by the fact that chunks of arraysx and cannot be correctly optimized The processor better utilizes hardware resources
Figures and indicate that this processor can execute kernel function in smaller number ofclock cycles
The higher performance and efficient cache memory cause that tilingoptimization can significantly change the time of kernel execution
Comparison ofthe same kernels for the same problem size for example Figures and revealsthat the number of cache misses is lower for the processor
As consequence evena small increase in memory cache misses can cause performance drop see Figures comparison of two cases with the same memory access pattern that are executed on the same hardware for example fissioned kernel executed on the processor Figures and reveals that optimal tile size is more dependent on the memoryaccess pattern than on the problem size
For both cases the minimal time of execution is if tile is within range and tile is within range
Figures and indicate that for these tile sizes the number of and is minimal
Thisfact can be explained by an analysis of memory access patterns
Data access forthe and arrays is optimized by tile
Meanwhile the and arrays areoptimized by tile
Array is two dimensional and it is optimized by tile andtile
The presented figures indicate that the optimal tile size lies within the regionwhere accesses for all arrays are optimized Hardware aware tiling optimization for multi core systems TILE Dependence between tile size and total number of data cache missesTILE Figure
Data cache misses for and forIntel Core Duo with PB and fused loops TILE TILE IDependence between tile size and kernel execution time in CPU clock cycles Figure
Time of kernel execution for IntelCore Duo with PB andfused loops TILE TILE IDependence between tile size and total number of data cache misses Figure
Data cache misses for and forIntel Core Duo with PB and fused loops TILE TILE Dependence between tile size and kernel execution time in CPU clock cycles Figure
Time of kernel execution for IntelCore Duo with PB andfused loops TILE Dependence between tile size and total number of data cache missesTILE Figure
Data cache misses for and forIntel Core Duo with PB and fissioned loops TILE TILE IDependence between tile size and kernel execution time in CPU clock cycles Figure
Time of kernel execution for IntelCore Duo with PB andfissioned loops Dominik Adamski Grzegorz Jab lon ski TILE Dependence between tile size and total number of data cache missesTILE Figure
Data cache misses for andL for Intel Core Duo withPB and fissioned loops TILE TILE IDependence between tile size and kernel execution time in CPU clock cycles Figure
Time of kernel execution for IntelCore Duo with PB andfissioned loops TILE TILE Dependence between tile size and total number of data cache misses Figure
Data cache misses for and for Intel with PB andfused loops TILE TILE IDependence between tile size and kernel execution time in CPU clock cycles Figure
Data cache misses for and for Intel with PB andfused loops TILE TILE IDependence between tile size and kernel execution time in CPU clock cycles Figure
Time of kernel execution for Intel with PB and fusedloops Hardware aware tiling optimization for multi core systems TILE TILE IDependence between tile size and total number of data cache misses Figure
Data cache misses for and for Intel with PB andfissioned loops TILE TILE Dependence between tile size and kernel execution time in CPU clock cycles Figure
Time of kernel execution for Inteli with PB and fissionedloops TILE TILE IDependence between tile size and total number of data cache misses Figure
Data cache misses for and for Intel with PB andfissioned loops TILE TILE Dependence between tile size and kernel execution time in CPU clock cycles Figure
Number of data cache missesfor Intel with PB andfissioned loops TILE Dependence between tile size and total number of data cache missesTILE Figure
Number of data cache missesfor Intel with PB andfissioned loops Dominik Adamski Grzegorz Jab lon skiFor both processors the biggest bottleneck is memory speed
Fissioned loops are executedin time comparable to the fused loops
If the tile size is wrongly chosen then thetime of execution of the fused loops can be longer than for the fissioned loops
ConclusionsTiling optimization can significantly reduce the number of data cache misses
Theexperimental results show that the efficiency of tiling is strongly dependent on memory access patterns for any given SCoP and hardware platform
Measurement dataindicates that code analysis cannot be skipped in optimized tile size analysis Experimental results have shown that tiling optimization cannot be focused onlyon single loop
Efficient tiling optimization should take into account the dependencies between neighboring and nested loops
SCoP analysis can indicate such regionsof code
This analysis can state if it is safe to tile given loop
It can also providesome information about the memory access patterns
This data can be used duringruntime for quick and accurate suboptimal tile size prediction Measurements indicate that the efficiency of tiling is hardware dependent
Execution of the same code on different hardware platforms causes the output results tobe different
In general tiling optimization can provide higher gain for powerfulprocessors
Figure indicates that for an Intel tiling optimization reduces thenumber of cache misses by double
For the older platform the dependency betweentile size and number of cache misses is weaker
This conclusion should be used inruntime design
If it is possible to detect such situation where the number of cachemisses does not change radically for multiple tile sizes then runtime should not spendmuch time on finding the most optimal tile size
In such case the coarse result willbe acceptable An efficient optimization procedure should take into account more parametersthan the number of data cache misses or execution time
There is strong need todefine holistic approach for efficient tiling optimization
This task is difficult because of the vast variety of hardware platforms
The dependencies between hardwarespecifications and executed software should be stated
It is vital to state which dependencies can be skipped during the optimization process
This simplification willlead to reduction in time which is necessary for the fine tuning of the tiled loop ReferencesIn Proceedings of the th International Conference on Parallel Architectures andCompilation Techniques PACT pp
Hardware aware tiling optimization for multi core systems Efficient FPGA Stencil Accelerators article presented during th InternationalWorkshop on Polyhedral Compilation Techniques http impact gforge inria fr impact papers impact deest pdf ject description available on webpage http icl cs utk edu papi index html gorithms
IEEE Computer Society Washington DC USA http dl acm org citation cfm id available on webpage http polly llvm org performance html Hexagonal Classical Tiling for GPUs
In Parallel ProcessingLetters vol
http dx doi org Polly Polyhedral optimization in LLVM
Chamonix France tative Approach Morgan Kaufmann Publishers San Francisco CA USA thed available on webpage http www intel com content dam www public us en documents product briefs xeon phi coprocessor system softwaredevelopers guide pdf Compiler Runtime Framework for Dynamic Dataflow Parallelization of TiledPrograms
In Proceedings of the International Symposium onCode Generation and Optimization Feedback directed and Runtime Optimization CGO pp
IEEE Computer Society Washington DC USA http dl acm org citation cfm id Dominik Adamski Grzegorz Jab lon skiProceedings of the th International Conference on Machine Learning andApplications Volume ICMLA pp
Figure available onwebpage http www karlrupp net wp content uploads yearsprocessor trend png Sarkar Analytical Bounds for Optimal Tile Size Selection
SpringerAffiliationsDominik AdamskiLodz University of Technology Department of Microelectronics and Computer ScienceGrzegorz Jab lon skiLodz University of Technology Department of Microelectronics and Computer ScienceReceived Revised Accepted
