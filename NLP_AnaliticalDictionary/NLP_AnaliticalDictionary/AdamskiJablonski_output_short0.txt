Computer Science http dx doi org csci Dominik AdamskiGrzegorz Jab lon skiHARDWARE AWARE TILING OPTIMIZATIONFOR MULTI CORE SYSTEMSAbstract This paper presents proposal new tool improves tiling efficiencyfor given hardware architecture
This article also describes correlationbetween changing hardware architecture methods software optimization
The first chapter includes short description change hardwarearchitecture occurred past ten years
The second chapterprovides overview tools used research
Thesubsequent sections contain description proposed hardware aware toolfor optimal tiling Keywords LLVM tiling data locality polyhedral modelCitation Computer Science Dominik Adamski Grzegorz Jab lon ski
IntroductionFor many decades speedup program execution achieved thespeedup processor clocks
The rapid growth processor clock frequencies causeda relatively small change architecture processors
Rapid growth processorfrequency stopped due heat dissipation issues
Since time hardwaremanufacturers shifted towards multi core architectures
They introduced advanced multi level cache memory systems multiplied number processor coresin single CPU unit
These changes reflected sophisticated processorarchitecture increasing number transistors used inside single CPU Unfortunately shift hardware architecture provide automaticspeedup software optimized sequential processing
Consequently new optimization method take account new target hardwarearchitectures
Modern compilers support parallel task execution theyshould provide new optimization methods would automatically detect parallelregions optimize order fully utilize hardware resources
There isa strong need develop techniques code optimization could easilydeployed various hardware architectures one hand take account themany specific hardware features different every target platform theother
Optimization methods meet goals easily deployed variousareas computer industry
They applied mobile devices theycan reduce power consumption prolong battery life
More effective software fordata centers reduce cost energy also decreasing data access time
Memory optimizationThe rapid increase processor computation power followed proportional memory speedup
As consequence overall speed program executionis limited memory latency
Multilevel memory organization allows us toreduce gap memory processor performance
Modern processors areequipped small amount quick cache memory placed near processor coreand larger amount slower cache shared many cores Unfortunately general model cache memory organization come alongwith increased variety processor architectures
GPU processors characterized multiple cores small amount shared cache memory distributedmemory model CPU processors use uniform memory model largeamount multilevel cache memory
In general memory usage optimization shouldaim exploit internal cache memory instead calling data slow external RAM memory
The number cache misses minimized well thenumber memory transfesr respective memory units Hardware aware tiling optimization multi core systems
Data localityDesigners processing units introduced multilevel system memory organization improve memory efficiency
They decided equip processing unitswith small amount fast cache memory
In modern CPUs multiple levelsof cache memory characterized different sizes speeds
The lower tiers cacheare fastest sizes smallest
Usually cooperate onecore
The higher tiers cache often shared multiple cores
Their sizesare bigger slower cache lower tier
If given variableis used many times processor placed lower cache
In case thewaiting time data reduced allowing processor perform faster calculations If processor requests data inside cache memory cache missevent occurs
In case processor wait data transportedfrom RAM memory
This situation substantially reduces performance theprocessing units
TilingOne available techniques improving memory performance tiling The main aim optimization maximally reuse fastest cache memory This goal achieved division large loop iteration space smallerrectangular parts tiles
Listing illustrates tiling optimization
The size thetiles chosen way cache misses minimized
It beenproven tile size chosen way number cache missesis minimized levels cache memory input source code int int optimized source code int int int ii ii min ii int jj jj min jj ii jj ii jj ii jj There many factors taken account choosing theoptimal tile size
This largely dependent target hardware platform
giventile size provide speedup calculations one target tilingconfiguration cause significant slowdown another target platform
On theother hand optimal tile size depends iteration space memory accesspatterns defined developer
In authors opinion also possible determine accurate analytical model optimal tiling prediction becauseof complexity hardware systems difficulties static analysis ofinput source code optimized Dominik Adamski Grzegorz Jab lon ski
State artCurrently code optimization multicore architectures center interest formany research teams large companies
They try develop tools would fullyutilize computational power multicore systems
Their research effort isfocused tools input code analysis
They also proposed new techniques forcode optimization
These techniques include automatic parallelization inputcode reduction cache misses
Polyhedral modelNowadays major compilers like GCC LLVM ICC MSVC equipped withtools detection loops parallelized
ICC MSVC compilers commercial products sources publicly available
For reason isnot possible accurately assess advantages drawbacks algorithms implemented products
GCC LLVM compilers open source aresome projects like Graphite GCC Polly LLVM use mathematicalconcept polyhedrons detecting parallel regions input code The main idea polyhedral model describe loops loop bodies interms mathematical equations
Loop boundary conditions modeled aslinear functions limit iteration space
The dimension iteration space equalto number nested loops
All data accesses inside loop body described interms iteration space coordinates
This mathematical model used optimizerswho trying find best schedule given loop Tools automatic code parallelization provide analytical methods detectingwhether given set loops executed parallel
This information important finding optimal loop tiling schedule broadening searchspace
It possible reorder loops parallel region increase data locality Such transformation simplify tiling analysis consequence appropriate tiling size found faster
The Polly compiler one tools forautomatic parallelization reorder sequence parallel loops improveddata locality
It also supports fixed tile size optimization optimization always profitable
Unfortunately Polly optimizations always leadto effective software
For cases tiling optimization decreases speed ofexecution programs
Analytical approachThe analytical approach finding optimal tile size based analysis inputsource code target hardware
Section Figure illustrates method ofoptimization
During compilation process compiler decide tilethe loops number cache misses minimized
The problem analyticallyfinding best partition data general case multilevel system cachememory classified NP hard
It possible determine finite timeHardware aware tiling optimization multi core systems place program data computer memory time necessary fordata transport minimal
The main difficulty lies number combinations thatshould analyzed
Therefore analytical models cover special cases forwhich possible determine optimal data schedule Insert runtime callbacks compileExecuteapplicationAnalyze optimize runtimesource codeBinarycodePerformancedataOptimizedcodeOptimize compileExecuteapplicationsource codeBinarycodeABFigure
Scheme statistical analytical approach optimization Analytical models divided two subcategories
The first subcategorycontains models predict optimal tile size strictly defined input source codepatterns
They try match input code given loop patterns whichit possible find optimal tile size
The second category based someheuristic simplification
The hardware modeled simplified way
Such simplification allows us find suboptimal tile size
The range simplification strictlycombined quality optimization
More general models find suboptimal tileresults faster
For models large risk obtaining poor optimizationresults
On hand sophisticated models require increased computation time finding suboptimal results may unacceptably long
Statistical approachStatistic methods finding suboptimal tile sizes also proposed They try predict optimal tile size basis previous results execution ofan optimized loop
Section Figure illustrates approach
This propositionrequires special runtime gathers information previous tile sizes andtheir corresponding execution times
Every time optimized loop executed theruntime tries provide effective tile size
This approach includeany theoretical models may require many invocations tiled loops find theoptimal tile size
Other approachesSome researchers propose shapes tiling rectangular
proposed hexagonal shape tiles GPU code
Another approach introduced Dominik Adamski Grzegorz Jab lon skiby Kong et al proposed minimization cache misses achievednot data tiling dynamic dataflow parallelization
Base tools hardware aware tilingAs mentioned previous section already tools try optimizethe data locality loops
They exist separate tools tools hasits strong weak points
In authors opinion worth combining ofthese methods one tool
This new tool based Polly compiler itsruntime measure cache misses PAPI library tested onthe Polybench benchmark
LLVM frameworkThe LLVM project started academic tool multi stage optimization Nowadays one leading open source compiler projects
It entirely writtenin characterized modular design
It also provides well documentedAPI
These features made LLVM oft chosen framework many compilerprojects
Figure presents internal relationship LLVM modules FrontendAda FrontendFortran FrontendX BackendARM BackendPowerPCBackendCommonOptimizerCAdaFortranARMPowerPCX Figure
LLVM architecture Front end modules responsible converting input source code simplerform analysis intermediate IR code
IR code independent high level inputlanguage
The simplified syntax IR code helps make data control flow analysiseasier compared source code analysis
It used hardware independentoptimization
All types IR optimization executed sequentially
The order ofexecution determined Pass Manager analyzes dependencies betweenpasses
Optimized IR code transferred backend modules generate targetspecific binary code Hardware aware tiling optimization multi core systems
Polly compilerThe Polly compiler project based LLVM framework
This compiler describes loops terms mathematical equations detects part codecan parallelized uses simplex method finding best schedule andthen generates parallelized code The Polly compiler automatically detects regions IR code parallelized
The code ready parallelization must satisfy following conditions These conditions allow compiler freely rearrange order statementexecution
Such rearrangement necessary tiling optimization
If loop isparallelizable loop tiling optimization safely performed Each detected parallel region described Static Control Part SCoP object Polly
These objects define iteration space parallel loops memoryaccess patterns inside loops data dependency elements loops This information used input polyhedral optimizers calculate anoptimal schedule given SCoP
Figure presents described architecture ofPolly LLVM Polly LLVM IRSCoP detection TransformationsScoplib Import ExportLLVM IRCode generationVectorizer BackendOpenMP parallel backendFigure
Architecture Polly compiler Dominik Adamski Grzegorz Jab lon ski
PAPI libraryThe PAPI library provides tools accurate measurement optimized loops It provides interface gathering information actual number cachemisses time loop execution
This data plays important role assessmentof quality optimized loops
If tile size badly chosen number ofcache misses high
PolybenchPolybench set benchmarks parallel kernels
These kernels correspondto popular matrix operations like matrix multiplication Fourier transform matrixcorrelation decomposition
Polybench source code used referencebenchmark proposed approach finding optimal tile sizes
Proposed solutionIt noticed statistical analytical approaches somedrawbacks
Theoretical considerations optimal tile size cannot give exactanswer tile size best statistical approach requires multipleexecution optimized loop method always provide speedupin loop execution
On hand polyhedral analysis used finding anoptimal loop schedule Polly compiler time memory consuming always provide best result In authors opinion worth combining tools static loop optimization dynamic tile selection
The Polly compiler used forthe static analysis input source code
It detect ready parallelizationregions IR code propose new schedule loop statements
Alloptimizations made Polly described SCoP object contains important data memory access patterns iteration space data dependency andthe proposed loop schedule
This information saved output binary codeand read runtime functions responsible choosing proper tilesize
The choice optimal tile size based heuristic data gatheredfrom previous executions analytical data static code analysis
Figure illustrates proposed solution The main aim approach provide data tile selectionmechanism
In authors opinion way combine static dynamicanalysis results
It expected combination give accuratemodel properly estimate optimal size loop tiling
The proposedtile size prediction method algorithm limit polyhedral optimization Tiled code still parallelized vectorized
The described optimization methodworks IR code combined machine specific optimization madeby target specific compiler backend Hardware aware tiling optimization multi core systems RuntimeSCoPInstrumentationPassInput SourceCodeProgramoutputCurrent settings SCoP informationPolyhedralAnalysisBinaryProgramNew tile sizeInstrumentedSCoPDetectedSCoPFigure
Architecture proposed solution The runtime algorithm used calculate optimal tile size specified
In authors opinion done last phase research
First mechanism saving static analysis results output binary code beimplemented
Without mechanism possible check artificialintelligence algorithm predicts optimal tile size best way The proposed approach allows us shorten selection time adding moredetailed code description obtained polyhedral analysis dynamic runtime selection algorithm
It expected compile time remain sameas standard polyhedral optimization
Runtime overhead increase duringprogram execution compared simple heuristic models analysisshould done choosing best tile size
On hand sophisticatedmethod finding best tile size could reduce number code executions neededto find optimal tile size This project also requires changes LLVM code
new pass beadded automatically insert runtime callbacks optimized loops
Thesecallbacks automatically adjust tile size based previous optimizationresults information hardware
Target platformsToday hardware manufacturers offer multiple solutions calculation acceleration Their architecture different worth providing general approach findingthe approximate optimal tile size
Currently three main trends designof computing efficient systems
Each different runtime ask forspecific values parameters platform separately Intel proposed new concept processor architecture called ManyIntegrated Core MIC architecture
This characterized multiple general purposeprocessors share cache memory
In comparison Haswell cores play therole coprocessor
Their role flexible work many configurations The type operation mode depends type processed algorithm
If algorithm easily parallelizable host processors offload portion Dominik Adamski Grzegorz Jab lon skicalculations coprocessors
If code cannot executed concurrently thenonly one host processor work
Tiling runtime take account howmany coprocessors available workload divided cores mode operation suitable GPU systems characterized distributed memory systems
The host processor offload calculations GPU
The offloading procedure requires datatransfer CPU GPU memory
This transfer strongly affects speedof calculations
Moreover processing units GPU optimized forstream processing
The tiling runtime take account numberof threads available target GPU
The best tile size effectively minimizethe number branches allow many threads possible executethe calculations parallel The third target platform combination traditional CPU processorwith Field Programmable Gate Array FPGA device Xilinx ZynQ
Thisapproach allows us offload calculations device easily tailored tothe end user computational needs
Recent research shows tiling improveusage available hardware
The runtime selecting best tile size theFPGA device take account results code analysis butalso available resources number available gates memory space memorybandwidth
Due long time necessary program FPGA device wouldprobably impossible tune tile size runtime
For platform runtimecan gather execution data like size used resources time kernelexecution propose best tile size kernel code againrecompiled bitstream code loaded FPGA device
Proof conceptThis section presents proof concept results
The methodology follows function presented listing manually tiled
For tested tilesize time function execution number data cache misses recordedby PAPI functions
They inserted beginning end thetest function code void test function int int int int int int PB PB PB PB PB Hardware aware tiling optimization multi core systems The Polly compiler detects loops described one SCoP
Asa consequence possible freely interchange loop order
There twovariants tiling optimization examined first concerns tiling loopseparately void test function int int int int int int PB int TILE int TILE TILE TILE define tile size PB TILE PB TILE ii ii MIN TILE PB ii jj jj MIN TILE PB jj ii ii ii jj jj PB TILE PB TILE ii ii MIN TILE PB ii jj jj MIN TILE PB jj ii ii ii jj jj The Polly compiler propose statements ii ii ii jj jj ii ii ii jj jj combined one loop
For reason following tiling schedule alsoanalyzed void test function int int int int int int PB int TILE int TILE TILE TILE define tile size PB TILE PB TILE ii ii MIN TILE PB ii jj jj MIN TILE PB jj ii ii ii jj jj ii ii ii jj jj Dominik Adamski Grzegorz Jab lon ski
Hardware platformsThe code compiled gcc executed without parallel optimization ontwo platforms
The first one Intel
This CPU MB level datacache
This PC equipped GB DDR RAM memory
The last level cachememory shared four cores
The first second levels cache memoryare dedicated one core
The second platform Intel Core Duo GB DDR RAM memory
This processor designed fornotebooks
It equipped level MB data cache memory
Both platforms runon Ubuntu
Empirical resultsThis section includes empirical results tiling efficiency
The first group plotsshows dependencies data cache misses tile size
The second group ofplots shows dependencies time kernel execution tile size The performed tests show tiling optimization hardware dependent
Figures show wide range tile sizes time ofexecution close minimal
This explained fact number ofcache misses comparable tile sizes Figures Time execution Intel Core Duo processor deteriorates tile isequal
For case processor executes many branch instructions causea significant slowdown
If tile equal number cache misses isconsiderably high
This situation explained fact chunks arraysx cannot correctly optimized The processor better utilizes hardware resources
Figures indicate processor execute kernel function smaller number ofclock cycles
The higher performance efficient cache memory cause tilingoptimization significantly change time kernel execution
Comparison ofthe kernels problem size example Figures revealsthat number cache misses lower processor
As consequence evena small increase memory cache misses cause performance drop see Figures comparison two cases memory access pattern executed hardware example fissioned kernel executed processor Figures reveals optimal tile size dependent memoryaccess pattern problem size
For cases minimal time execution tile within range tile within range
Figures indicate tile sizes number minimal
Thisfact explained analysis memory access patterns
Data access forthe arrays optimized tile
Meanwhile arrays areoptimized tile
Array two dimensional optimized tile andtile
The presented figures indicate optimal tile size lies within regionwhere accesses arrays optimized Hardware aware tiling optimization multi core systems TILE Dependence tile size total number data cache missesTILE Figure
Data cache misses forIntel Core Duo PB fused loops TILE TILE IDependence tile size kernel execution time CPU clock cycles Figure
Time kernel execution IntelCore Duo PB andfused loops TILE TILE IDependence tile size total number data cache misses Figure
Data cache misses forIntel Core Duo PB fused loops TILE TILE Dependence tile size kernel execution time CPU clock cycles Figure
Time kernel execution IntelCore Duo PB andfused loops TILE Dependence tile size total number data cache missesTILE Figure
Data cache misses forIntel Core Duo PB fissioned loops TILE TILE IDependence tile size kernel execution time CPU clock cycles Figure
Time kernel execution IntelCore Duo PB andfissioned loops Dominik Adamski Grzegorz Jab lon ski TILE Dependence tile size total number data cache missesTILE Figure
Data cache misses andL Intel Core Duo withPB fissioned loops TILE TILE IDependence tile size kernel execution time CPU clock cycles Figure
Time kernel execution IntelCore Duo PB andfissioned loops TILE TILE Dependence tile size total number data cache misses Figure
Data cache misses Intel PB andfused loops TILE TILE IDependence tile size kernel execution time CPU clock cycles Figure
Data cache misses Intel PB andfused loops TILE TILE IDependence tile size kernel execution time CPU clock cycles Figure
Time kernel execution Intel PB fusedloops Hardware aware tiling optimization multi core systems TILE TILE IDependence tile size total number data cache misses Figure
Data cache misses Intel PB andfissioned loops TILE TILE Dependence tile size kernel execution time CPU clock cycles Figure
Time kernel execution Inteli PB fissionedloops TILE TILE IDependence tile size total number data cache misses Figure
Data cache misses Intel PB andfissioned loops TILE TILE Dependence tile size kernel execution time CPU clock cycles Figure
Number data cache missesfor Intel PB andfissioned loops TILE Dependence tile size total number data cache missesTILE Figure
Number data cache missesfor Intel PB andfissioned loops Dominik Adamski Grzegorz Jab lon skiFor processors biggest bottleneck memory speed
Fissioned loops executedin time comparable fused loops
If tile size wrongly chosen thetime execution fused loops longer fissioned loops
ConclusionsTiling optimization significantly reduce number data cache misses
Theexperimental results show efficiency tiling strongly dependent memory access patterns given SCoP hardware platform
Measurement dataindicates code analysis cannot skipped optimized tile size analysis Experimental results shown tiling optimization cannot focused onlyon single loop
Efficient tiling optimization take account dependencies neighboring nested loops
SCoP analysis indicate regionsof code
This analysis state safe tile given loop
It also providesome information memory access patterns
This data used duringruntime quick accurate suboptimal tile size prediction Measurements indicate efficiency tiling hardware dependent
Execution code different hardware platforms causes output results tobe different
In general tiling optimization provide higher gain powerfulprocessors
Figure indicates Intel tiling optimization reduces thenumber cache misses double
For older platform dependency betweentile size number cache misses weaker
This conclusion used inruntime design
If possible detect situation number cachemisses change radically multiple tile sizes runtime spendmuch time finding optimal tile size
In case coarse result willbe acceptable An efficient optimization procedure take account parametersthan number data cache misses execution time
There strong need todefine holistic approach efficient tiling optimization
This task difficult vast variety hardware platforms
The dependencies hardwarespecifications executed software stated
It vital state dependencies skipped optimization process
This simplification willlead reduction time necessary fine tuning tiled loop ReferencesIn Proceedings th International Conference Parallel Architectures andCompilation Techniques PACT pp
Hardware aware tiling optimization multi core systems Efficient FPGA Stencil Accelerators article presented th InternationalWorkshop Polyhedral Compilation Techniques http impact gforge inria fr impact papers impact deest pdf ject description available webpage http icl cs utk edu papi index html gorithms
IEEE Computer Society Washington DC USA http dl acm org citation cfm id available webpage http polly llvm org performance html Hexagonal Classical Tiling GPUs
In Parallel ProcessingLetters vol
http dx doi org Polly Polyhedral optimization LLVM
Chamonix France tative Approach Morgan Kaufmann Publishers San Francisco CA USA thed available webpage http www intel com content dam www public us en documents product briefs xeon phi coprocessor system softwaredevelopers guide pdf Compiler Runtime Framework Dynamic Dataflow Parallelization TiledPrograms
In Proceedings International Symposium onCode Generation Optimization Feedback directed Runtime Optimization CGO pp
IEEE Computer Society Washington DC USA http dl acm org citation cfm id Dominik Adamski Grzegorz Jab lon skiProceedings th International Conference Machine Learning andApplications Volume ICMLA pp
Figure available onwebpage http www karlrupp net wp content uploads yearsprocessor trend png Sarkar Analytical Bounds Optimal Tile Size Selection
SpringerAffiliationsDominik AdamskiLodz University Technology Department Microelectronics Computer ScienceGrzegorz Jab lon skiLodz University Technology Department Microelectronics Computer ScienceReceived Revised Accepted
